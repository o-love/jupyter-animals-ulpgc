{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:19:48.636269Z",
     "iopub.status.busy": "2022-12-24T09:19:48.635334Z",
     "iopub.status.idle": "2022-12-24T09:19:55.774175Z",
     "shell.execute_reply": "2022-12-24T09:19:55.773232Z",
     "shell.execute_reply.started": "2022-12-24T09:19:48.636181Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow\n",
    "tensorflow.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:19:55.784405Z",
     "iopub.status.busy": "2022-12-24T09:19:55.782032Z",
     "iopub.status.idle": "2022-12-24T09:19:56.280810Z",
     "shell.execute_reply": "2022-12-24T09:19:56.279812Z",
     "shell.execute_reply.started": "2022-12-24T09:19:55.784368Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "basedir = 'C:/Users/olabr/Downloads/aminals dataset'\n",
    "\n",
    "%matplotlib inline\n",
    "pil_im = Image.open(basedir + '/Test/Zebra/Zebra-Test (7).jpeg', 'r')\n",
    "\n",
    "imshow(np.asarray(pil_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-24T09:19:56.282927Z",
     "iopub.status.busy": "2022-12-24T09:19:56.282055Z",
     "iopub.status.idle": "2022-12-24T09:19:57.311557Z",
     "shell.execute_reply": "2022-12-24T09:19:57.310355Z",
     "shell.execute_reply.started": "2022-12-24T09:19:56.282873Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from time import time\n",
    "\n",
    "# DATA SOURCE --------------------------------------------------\n",
    "\n",
    "train_data_dir = basedir + '/Train'\n",
    "validation_data_dir = basedir + '/Valid'\n",
    "test_data_dir = basedir + '/Test'\n",
    "image_size = (256, 256)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:19:57.316200Z",
     "iopub.status.busy": "2022-12-24T09:19:57.314240Z",
     "iopub.status.idle": "2022-12-24T09:20:06.385598Z",
     "shell.execute_reply": "2022-12-24T09:20:06.384518Z",
     "shell.execute_reply.started": "2022-12-24T09:19:57.316158Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    #validation_split=0.2,\n",
    "    #subset=\"training\",\n",
    "    #seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_ds = tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_data_dir,\n",
    "    #validation_split=0.2,\n",
    "    #subset=\"validation\",\n",
    "    #seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "test_ds = tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    #validation_split=0.2,\n",
    "    #subset=\"validation\",\n",
    "    #seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=64)\n",
    "validation_ds = validation_ds.prefetch(buffer_size=32)\n",
    "test_ds = test_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:20:06.389326Z",
     "iopub.status.busy": "2022-12-24T09:20:06.388791Z",
     "iopub.status.idle": "2022-12-24T09:20:06.396328Z",
     "shell.execute_reply": "2022-12-24T09:20:06.395394Z",
     "shell.execute_reply.started": "2022-12-24T09:20:06.389291Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#train_datagen = ImageDataGenerator(\n",
    "#        rescale=1./255,\n",
    "#        rotation_range=15,\n",
    "#        zoom_range=0.1\n",
    "#)\n",
    "\n",
    "#validation_datagen = ImageDataGenerator(\n",
    "#        rescale=1./255\n",
    "#)\n",
    "\n",
    "\n",
    "#train_ds_augmentation = train_datagen.flow_from_directory(\n",
    "#    train_data_dir,\n",
    "#    #validation_split=0.2,\n",
    "#    #subset=\"training\",\n",
    "#    #seed=1337,\n",
    "#    target_size=image_size,\n",
    "#    batch_size=batch_size,\n",
    "#    class_mode='categorical'\n",
    "#)\n",
    "\n",
    "#validation_ds_augmentation = validation_datagen.flow_from_directory(\n",
    "#    validation_data_dir,\n",
    "#    #validation_split=0.2,\n",
    "#    #subset=\"validation\",\n",
    "#    #seed=1337,\n",
    "#    target_size=image_size,\n",
    "#    batch_size=batch_size,\n",
    "#    class_mode='categorical'\n",
    "#)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-24T09:36:53.948574Z",
     "iopub.status.busy": "2022-12-24T09:36:53.947690Z",
     "iopub.status.idle": "2022-12-24T09:36:54.976461Z",
     "shell.execute_reply": "2022-12-24T09:36:54.975411Z",
     "shell.execute_reply.started": "2022-12-24T09:36:53.948536Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow import keras\n",
    "\n",
    "# MODEL --------------------------------------------------\n",
    "\n",
    "def build_model(denseVal):\n",
    "    base_model = VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                       input_shape=(256, 256, 3),\n",
    "                       include_top=False\n",
    "                       )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = keras.applications.mobilenet.preprocess_input(inputs)\n",
    "\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = keras.layers.Dense(units=denseVal, activation='relu', kernel_initializer='he_normal')(x)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tensorflow.keras.optimizers.Adam(1e-3),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(hp):\n",
    "    return build_model(hp.Int(\"units\", min_value=32, max_value=2048, step=32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_model(1600);\n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-24T09:36:59.564578Z",
     "iopub.status.busy": "2022-12-24T09:36:59.563895Z",
     "iopub.status.idle": "2022-12-24T09:36:59.576231Z",
     "shell.execute_reply": "2022-12-24T09:36:59.574972Z",
     "shell.execute_reply.started": "2022-12-24T09:36:59.564543Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "\n",
    "tuner = keras_tuner.Hyperband (\n",
    "    hypermodel=train_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    directory=\"tuner\"\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(train_ds, epochs=2, validation_data=(validation_ds))\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING --------------------------------------------------\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "          train_ds,\n",
    "          epochs=epochs,\n",
    "          validation_data = validation_ds,\n",
    "          callbacks = [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-24T09:31:25.166666Z",
     "iopub.status.busy": "2022-12-24T09:31:25.165725Z",
     "iopub.status.idle": "2022-12-24T09:31:25.367687Z",
     "shell.execute_reply": "2022-12-24T09:31:25.366257Z",
     "shell.execute_reply.started": "2022-12-24T09:31:25.166627Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVING --------------------------------------------------\n",
    "\n",
    "model.save(\"models/vgg_one_layer_dropout_v3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Evaluación de resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:31:25.376939Z",
     "iopub.status.busy": "2022-12-24T09:31:25.375782Z",
     "iopub.status.idle": "2022-12-24T09:31:45.398644Z",
     "shell.execute_reply": "2022-12-24T09:31:45.397701Z",
     "shell.execute_reply.started": "2022-12-24T09:31:25.376874Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "results = np.concatenate([(y, model.predict(x=x)) for x, y in validation_ds], axis=1)\n",
    "\n",
    "labels = np.argmax(results[0], axis=1)\n",
    "predictions = np.argmax(results[1], axis=1)\n",
    "\n",
    "cf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix)\n",
    "#disp.plot()\n",
    "\n",
    "print(classification_report(labels, predictions, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:31:45.402170Z",
     "iopub.status.busy": "2022-12-24T09:31:45.400049Z",
     "iopub.status.idle": "2022-12-24T09:31:45.609758Z",
     "shell.execute_reply": "2022-12-24T09:31:45.608861Z",
     "shell.execute_reply.started": "2022-12-24T09:31:45.402131Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "\n",
    "plt.title('Entrenamiento Sign-language Digits')\n",
    "\n",
    "\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:31:45.615171Z",
     "iopub.status.busy": "2022-12-24T09:31:45.613515Z",
     "iopub.status.idle": "2022-12-24T09:31:45.980002Z",
     "shell.execute_reply": "2022-12-24T09:31:45.979147Z",
     "shell.execute_reply.started": "2022-12-24T09:31:45.615128Z"
    }
   },
   "outputs": [],
   "source": [
    "# PRODUCTION ----------------------------------------------\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow.keras\n",
    "\n",
    "# LOADING --------------------------------------------------\n",
    "#model = tensorflow.keras.models.load_model(\"mimodelo.h5\")\n",
    "\n",
    "etiquetas=['Baked Potato', 'Burger', 'Crispy Chicken', 'Donut', 'Hot Dog', 'Pizza', 'Sandwich', 'Taco']\n",
    "%matplotlib inline\n",
    "\n",
    "pil_im = Image.open(basedir + '/Test/Burger/Burger-Test (10).jpeg', 'r')\n",
    "im = np.asarray(pil_im.resize((256, 256)))\n",
    "imshow(im)\n",
    "print(im.shape) # La imagen es un array de dimensión: 150x150x3 (256x256x3)\n",
    "\n",
    "# El método `predict` hace la predicción de un lote de entradas, no solo una. \n",
    "# En el caso de que tengamos solo una entrada deberemos añadirle una dimensión más \n",
    "# al array numpy para que la entrada tenga la dimensión: 1x150x150x3\n",
    "\n",
    "im = im.reshape(1,256, 256,3)\n",
    "\n",
    "\n",
    "print('El vector de salida obtenido: ', model.predict(im))\n",
    "print('La etiqueta de salida predicha es ', np.argmax(model.predict(im)))\n",
    "print('Ahora dicho con texto: La etiqueta de salida predicha es ', etiquetas[np.argmax(model.predict(im))])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:31:45.982141Z",
     "iopub.status.busy": "2022-12-24T09:31:45.981524Z",
     "iopub.status.idle": "2022-12-24T09:31:54.544687Z",
     "shell.execute_reply": "2022-12-24T09:31:54.543595Z",
     "shell.execute_reply.started": "2022-12-24T09:31:45.982087Z"
    }
   },
   "outputs": [],
   "source": [
    "# PRODUCTION ----------------------------------------------\n",
    "\n",
    "#from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import tensorflow.keras\n",
    "\n",
    "# SAVING --------------------------------------------------\n",
    "#model.save_model(\"mimodelo.h5\")\n",
    "\n",
    "\n",
    "# LOADING --------------------------------------------------\n",
    "#model = tensorflow.keras.models.load_model(\"mimodelo.h5\")\n",
    "\n",
    "etiquetas=['Baked Potato', 'Burger', 'Crispy Chicken', 'Donut', 'Fries', 'Hot Dog', 'Pizza', 'Sandwich', 'Taco', 'Taquito']\n",
    "%matplotlib inline\n",
    "print(\"ETIQUETA PREDICHA -> ETIQUETA REAL\")\n",
    "for minilote in test_ds:\n",
    "    prediccion_minilote = model.predict(minilote[0].numpy())\n",
    "    etiqueta_real_minilote = minilote[1].numpy()\n",
    "    for y_predicha, y_real in zip(np.round(prediccion_minilote,3), etiqueta_real_minilote):\n",
    "        if np.argmax(y_predicha) == np.argmax(y_real):\n",
    "            print(etiquetas[np.argmax(y_predicha)], \"->\", etiquetas[np.argmax(y_real)])\n",
    "        else:\n",
    "            print(etiquetas[np.argmax(y_predicha)], \"->\", etiquetas[np.argmax(y_real)], \"✘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
